{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Music_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLBmj84XGagR"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "#Libraries to pre-process the variables\n",
        "from sklearn.preprocessing import LabelEncoder,MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pickle import dump"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XM9IovlMhu0t"
      },
      "source": [
        "#Libraries to create the Multi-class Neural Network\n",
        "from keras.models import Sequential\n",
        "from keras.regularizers import l1, l2\n",
        "from keras.layers import Dense, Dropout, InputLayer\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luUSGia-i1kL",
        "outputId": "24f02dbc-857a-4f68-d096-2728f5f79a72"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#4/1AX4XfWgeHyWFoJRwuStTP-EUbQngtl_nOxMD5lPbebfFAk8pcXTWD5IqrT8"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_GlJ0Aqi2e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "outputId": "218aadf4-1e91-4df0-cb1a-aa55b2d4d158"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/moods.csv') \n",
        "df.head(2)\n",
        "#happy sad neutral anger suprised"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>album</th>\n",
              "      <th>artist</th>\n",
              "      <th>id</th>\n",
              "      <th>release_date</th>\n",
              "      <th>popularity</th>\n",
              "      <th>length</th>\n",
              "      <th>danceability</th>\n",
              "      <th>acousticness</th>\n",
              "      <th>energy</th>\n",
              "      <th>instrumentalness</th>\n",
              "      <th>liveness</th>\n",
              "      <th>valence</th>\n",
              "      <th>loudness</th>\n",
              "      <th>speechiness</th>\n",
              "      <th>tempo</th>\n",
              "      <th>key</th>\n",
              "      <th>time_signature</th>\n",
              "      <th>mood</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1999</td>\n",
              "      <td>1999</td>\n",
              "      <td>Prince</td>\n",
              "      <td>2H7PHVdQ3mXqEHXcvclTB0</td>\n",
              "      <td>1982-10-27</td>\n",
              "      <td>68</td>\n",
              "      <td>379266</td>\n",
              "      <td>0.866</td>\n",
              "      <td>0.1370</td>\n",
              "      <td>0.730</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0843</td>\n",
              "      <td>0.625</td>\n",
              "      <td>-8.201</td>\n",
              "      <td>0.0767</td>\n",
              "      <td>118.523</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>Happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>23</td>\n",
              "      <td>23</td>\n",
              "      <td>Blonde Redhead</td>\n",
              "      <td>4HIwL9ii9CcXpTOTzMq0MP</td>\n",
              "      <td>2007-04-16</td>\n",
              "      <td>43</td>\n",
              "      <td>318800</td>\n",
              "      <td>0.381</td>\n",
              "      <td>0.0189</td>\n",
              "      <td>0.832</td>\n",
              "      <td>0.196</td>\n",
              "      <td>0.1530</td>\n",
              "      <td>0.166</td>\n",
              "      <td>-5.069</td>\n",
              "      <td>0.0492</td>\n",
              "      <td>120.255</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>Sad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   name album          artist  ... key time_signature   mood\n",
              "0  1999  1999          Prince  ...   5              4  Happy\n",
              "1    23    23  Blonde Redhead  ...   8              4    Sad\n",
              "\n",
              "[2 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEJFLzULjdun"
      },
      "source": [
        "Y = df['mood']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY-CZEpCkJfv"
      },
      "source": [
        "df.drop(axis = 1, columns = ['name', 'album','mood', 'artist', 'id', 'release_date', 'popularity', 'length', 'liveness', 'tempo', 'key', 'time_signature'], inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og-p16NakdPk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "7e0fe241-4b46-4f4a-8acb-c72361f2bee4"
      },
      "source": [
        "X = df\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>danceability</th>\n",
              "      <th>acousticness</th>\n",
              "      <th>energy</th>\n",
              "      <th>instrumentalness</th>\n",
              "      <th>valence</th>\n",
              "      <th>loudness</th>\n",
              "      <th>speechiness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.866</td>\n",
              "      <td>0.13700</td>\n",
              "      <td>0.7300</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.6250</td>\n",
              "      <td>-8.201</td>\n",
              "      <td>0.0767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.381</td>\n",
              "      <td>0.01890</td>\n",
              "      <td>0.8320</td>\n",
              "      <td>0.196000</td>\n",
              "      <td>0.1660</td>\n",
              "      <td>-5.069</td>\n",
              "      <td>0.0492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.346</td>\n",
              "      <td>0.91300</td>\n",
              "      <td>0.1390</td>\n",
              "      <td>0.000077</td>\n",
              "      <td>0.1160</td>\n",
              "      <td>-15.326</td>\n",
              "      <td>0.0321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.466</td>\n",
              "      <td>0.08900</td>\n",
              "      <td>0.4380</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.5870</td>\n",
              "      <td>-12.858</td>\n",
              "      <td>0.0608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.419</td>\n",
              "      <td>0.00171</td>\n",
              "      <td>0.9320</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.4450</td>\n",
              "      <td>-3.604</td>\n",
              "      <td>0.1060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>681</th>\n",
              "      <td>0.402</td>\n",
              "      <td>0.96100</td>\n",
              "      <td>0.2360</td>\n",
              "      <td>0.919000</td>\n",
              "      <td>0.1460</td>\n",
              "      <td>-20.615</td>\n",
              "      <td>0.0603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>682</th>\n",
              "      <td>0.452</td>\n",
              "      <td>0.75700</td>\n",
              "      <td>0.5150</td>\n",
              "      <td>0.120000</td>\n",
              "      <td>0.1910</td>\n",
              "      <td>-7.351</td>\n",
              "      <td>0.0255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>683</th>\n",
              "      <td>0.642</td>\n",
              "      <td>0.78600</td>\n",
              "      <td>0.3740</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0799</td>\n",
              "      <td>-9.386</td>\n",
              "      <td>0.0545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>684</th>\n",
              "      <td>0.561</td>\n",
              "      <td>0.91300</td>\n",
              "      <td>0.0848</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>-15.099</td>\n",
              "      <td>0.0404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>685</th>\n",
              "      <td>0.377</td>\n",
              "      <td>0.99400</td>\n",
              "      <td>0.0156</td>\n",
              "      <td>0.881000</td>\n",
              "      <td>0.0804</td>\n",
              "      <td>-28.435</td>\n",
              "      <td>0.0397</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>686 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     danceability  acousticness  energy  ...  valence  loudness  speechiness\n",
              "0           0.866       0.13700  0.7300  ...   0.6250    -8.201       0.0767\n",
              "1           0.381       0.01890  0.8320  ...   0.1660    -5.069       0.0492\n",
              "2           0.346       0.91300  0.1390  ...   0.1160   -15.326       0.0321\n",
              "3           0.466       0.08900  0.4380  ...   0.5870   -12.858       0.0608\n",
              "4           0.419       0.00171  0.9320  ...   0.4450    -3.604       0.1060\n",
              "..            ...           ...     ...  ...      ...       ...          ...\n",
              "681         0.402       0.96100  0.2360  ...   0.1460   -20.615       0.0603\n",
              "682         0.452       0.75700  0.5150  ...   0.1910    -7.351       0.0255\n",
              "683         0.642       0.78600  0.3740  ...   0.0799    -9.386       0.0545\n",
              "684         0.561       0.91300  0.0848  ...   0.2060   -15.099       0.0404\n",
              "685         0.377       0.99400  0.0156  ...   0.0804   -28.435       0.0397\n",
              "\n",
              "[686 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQKH_x4Lk2t-"
      },
      "source": [
        "scaler = MinMaxScaler().fit(X)\n",
        "X = scaler.transform(X)\n",
        "dump(scaler, open('scaler.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BHibfhelSwK"
      },
      "source": [
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "Y = encoder.transform(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eel3wa8lVX7"
      },
      "source": [
        "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5A1Rs0fDllNQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e36dfb17-ad38-4583-8601-cf4cf149c2f4"
      },
      "source": [
        "model = Sequential([  \n",
        "  InputLayer(input_shape=7),\n",
        "  Dense(5, activation = 'relu'),\n",
        "  Dense(4, activation = 'softmax')\n",
        "  ])\n",
        "opt = tf.keras.optimizers.Adam(learning_rate = 0.005)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath = '/content/drive/MyDrive/Moodify/music_weights.hdf5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 5)                 40        \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 4)                 24        \n",
            "=================================================================\n",
            "Total params: 64\n",
            "Trainable params: 64\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVfdGAZprznA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ef846b89-1516-4692-8fc3-c437fa0ed885"
      },
      "source": [
        "History=model.fit(X_train,Y_train, batch_size=100, epochs=300, verbose=2,validation_split = 0.1, callbacks=[checkpoint])\n",
        "plt.title(\"accuracy histoy\")\n",
        "index=[i for i in range(len(History.history['accuracy']))]\n",
        "plt.plot(index,History.history['accuracy'],label='train')\n",
        "plt.plot(index,History.history['val_accuracy'],label='validation')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()\n",
        "plt.title(\"loss histoy\")\n",
        "plt.plot(index,History.history['loss'], label='train')\n",
        "plt.plot(index,History.history['val_loss'], label='validation')\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "5/5 - 1s - loss: 1.2269 - accuracy: 0.5294 - val_loss: 1.1754 - val_accuracy: 0.5818\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.58182, saving model to /content/drive/MyDrive/Moodify/music_weights.hdf5\n",
            "Epoch 2/300\n",
            "5/5 - 0s - loss: 1.1856 - accuracy: 0.5984 - val_loss: 1.1462 - val_accuracy: 0.5273\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.58182\n",
            "Epoch 3/300\n",
            "5/5 - 0s - loss: 1.1507 - accuracy: 0.6207 - val_loss: 1.1191 - val_accuracy: 0.5091\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.58182\n",
            "Epoch 4/300\n",
            "5/5 - 0s - loss: 1.1190 - accuracy: 0.6410 - val_loss: 1.0920 - val_accuracy: 0.5455\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.58182\n",
            "Epoch 5/300\n",
            "5/5 - 0s - loss: 1.0885 - accuracy: 0.6491 - val_loss: 1.0649 - val_accuracy: 0.5818\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.58182\n",
            "Epoch 6/300\n",
            "5/5 - 0s - loss: 1.0594 - accuracy: 0.6511 - val_loss: 1.0388 - val_accuracy: 0.5818\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.58182\n",
            "Epoch 7/300\n",
            "5/5 - 0s - loss: 1.0309 - accuracy: 0.6592 - val_loss: 1.0138 - val_accuracy: 0.5818\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.58182\n",
            "Epoch 8/300\n",
            "5/5 - 0s - loss: 1.0038 - accuracy: 0.6572 - val_loss: 0.9899 - val_accuracy: 0.5818\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.58182\n",
            "Epoch 9/300\n",
            "5/5 - 0s - loss: 0.9784 - accuracy: 0.6613 - val_loss: 0.9672 - val_accuracy: 0.5818\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.58182\n",
            "Epoch 10/300\n",
            "5/5 - 0s - loss: 0.9539 - accuracy: 0.6653 - val_loss: 0.9466 - val_accuracy: 0.5818\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.58182\n",
            "Epoch 11/300\n",
            "5/5 - 0s - loss: 0.9301 - accuracy: 0.6694 - val_loss: 0.9277 - val_accuracy: 0.5818\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.58182\n",
            "Epoch 12/300\n",
            "5/5 - 0s - loss: 0.9076 - accuracy: 0.6795 - val_loss: 0.9082 - val_accuracy: 0.5818\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.58182\n",
            "Epoch 13/300\n",
            "5/5 - 0s - loss: 0.8862 - accuracy: 0.6876 - val_loss: 0.8909 - val_accuracy: 0.6000\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.58182 to 0.60000, saving model to /content/drive/MyDrive/Moodify/music_weights.hdf5\n",
            "Epoch 14/300\n",
            "5/5 - 0s - loss: 0.8658 - accuracy: 0.6856 - val_loss: 0.8729 - val_accuracy: 0.6000\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.60000\n",
            "Epoch 15/300\n",
            "5/5 - 0s - loss: 0.8465 - accuracy: 0.6957 - val_loss: 0.8576 - val_accuracy: 0.6000\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.60000\n",
            "Epoch 16/300\n",
            "5/5 - 0s - loss: 0.8286 - accuracy: 0.7018 - val_loss: 0.8431 - val_accuracy: 0.6000\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.60000\n",
            "Epoch 17/300\n",
            "5/5 - 0s - loss: 0.8116 - accuracy: 0.7039 - val_loss: 0.8301 - val_accuracy: 0.6000\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.60000\n",
            "Epoch 18/300\n",
            "5/5 - 0s - loss: 0.7950 - accuracy: 0.7079 - val_loss: 0.8174 - val_accuracy: 0.6000\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.60000\n",
            "Epoch 19/300\n",
            "5/5 - 0s - loss: 0.7796 - accuracy: 0.7120 - val_loss: 0.8050 - val_accuracy: 0.6000\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.60000\n",
            "Epoch 20/300\n",
            "5/5 - 0s - loss: 0.7656 - accuracy: 0.7282 - val_loss: 0.7927 - val_accuracy: 0.6000\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.60000\n",
            "Epoch 21/300\n",
            "5/5 - 0s - loss: 0.7516 - accuracy: 0.7323 - val_loss: 0.7828 - val_accuracy: 0.6000\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.60000\n",
            "Epoch 22/300\n",
            "5/5 - 0s - loss: 0.7385 - accuracy: 0.7323 - val_loss: 0.7721 - val_accuracy: 0.6182\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.60000 to 0.61818, saving model to /content/drive/MyDrive/Moodify/music_weights.hdf5\n",
            "Epoch 23/300\n",
            "5/5 - 0s - loss: 0.7261 - accuracy: 0.7465 - val_loss: 0.7628 - val_accuracy: 0.6000\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.61818\n",
            "Epoch 24/300\n",
            "5/5 - 0s - loss: 0.7139 - accuracy: 0.7505 - val_loss: 0.7551 - val_accuracy: 0.6000\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.61818\n",
            "Epoch 25/300\n",
            "5/5 - 0s - loss: 0.7027 - accuracy: 0.7586 - val_loss: 0.7461 - val_accuracy: 0.6000\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.61818\n",
            "Epoch 26/300\n",
            "5/5 - 0s - loss: 0.6914 - accuracy: 0.7586 - val_loss: 0.7373 - val_accuracy: 0.6000\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.61818\n",
            "Epoch 27/300\n",
            "5/5 - 0s - loss: 0.6797 - accuracy: 0.7586 - val_loss: 0.7312 - val_accuracy: 0.6000\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.61818\n",
            "Epoch 28/300\n",
            "5/5 - 0s - loss: 0.6687 - accuracy: 0.7586 - val_loss: 0.7256 - val_accuracy: 0.5818\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.61818\n",
            "Epoch 29/300\n",
            "5/5 - 0s - loss: 0.6588 - accuracy: 0.7586 - val_loss: 0.7188 - val_accuracy: 0.5818\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.61818\n",
            "Epoch 30/300\n",
            "5/5 - 0s - loss: 0.6481 - accuracy: 0.7586 - val_loss: 0.7088 - val_accuracy: 0.6182\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.61818\n",
            "Epoch 31/300\n",
            "5/5 - 0s - loss: 0.6384 - accuracy: 0.7627 - val_loss: 0.7005 - val_accuracy: 0.6182\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.61818\n",
            "Epoch 32/300\n",
            "5/5 - 0s - loss: 0.6293 - accuracy: 0.7647 - val_loss: 0.6946 - val_accuracy: 0.6182\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.61818\n",
            "Epoch 33/300\n",
            "5/5 - 0s - loss: 0.6214 - accuracy: 0.7708 - val_loss: 0.6891 - val_accuracy: 0.6182\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.61818\n",
            "Epoch 34/300\n",
            "5/5 - 0s - loss: 0.6124 - accuracy: 0.7769 - val_loss: 0.6826 - val_accuracy: 0.6182\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.61818\n",
            "Epoch 35/300\n",
            "5/5 - 0s - loss: 0.6049 - accuracy: 0.7728 - val_loss: 0.6788 - val_accuracy: 0.6364\n",
            "\n",
            "Epoch 00035: val_accuracy improved from 0.61818 to 0.63636, saving model to /content/drive/MyDrive/Moodify/music_weights.hdf5\n",
            "Epoch 36/300\n",
            "5/5 - 0s - loss: 0.5982 - accuracy: 0.7688 - val_loss: 0.6766 - val_accuracy: 0.6182\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.63636\n",
            "Epoch 37/300\n",
            "5/5 - 0s - loss: 0.5907 - accuracy: 0.7748 - val_loss: 0.6686 - val_accuracy: 0.6182\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.63636\n",
            "Epoch 38/300\n",
            "5/5 - 0s - loss: 0.5844 - accuracy: 0.7850 - val_loss: 0.6612 - val_accuracy: 0.6545\n",
            "\n",
            "Epoch 00038: val_accuracy improved from 0.63636 to 0.65455, saving model to /content/drive/MyDrive/Moodify/music_weights.hdf5\n",
            "Epoch 39/300\n",
            "5/5 - 0s - loss: 0.5781 - accuracy: 0.7850 - val_loss: 0.6566 - val_accuracy: 0.6545\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.65455\n",
            "Epoch 40/300\n",
            "5/5 - 0s - loss: 0.5723 - accuracy: 0.7911 - val_loss: 0.6553 - val_accuracy: 0.6545\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.65455\n",
            "Epoch 41/300\n",
            "5/5 - 0s - loss: 0.5670 - accuracy: 0.7870 - val_loss: 0.6517 - val_accuracy: 0.6182\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.65455\n",
            "Epoch 42/300\n",
            "5/5 - 0s - loss: 0.5618 - accuracy: 0.7870 - val_loss: 0.6491 - val_accuracy: 0.6000\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.65455\n",
            "Epoch 43/300\n",
            "5/5 - 0s - loss: 0.5573 - accuracy: 0.7931 - val_loss: 0.6439 - val_accuracy: 0.6545\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.65455\n",
            "Epoch 44/300\n",
            "5/5 - 0s - loss: 0.5525 - accuracy: 0.7931 - val_loss: 0.6409 - val_accuracy: 0.6545\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.65455\n",
            "Epoch 45/300\n",
            "5/5 - 0s - loss: 0.5480 - accuracy: 0.7992 - val_loss: 0.6379 - val_accuracy: 0.6545\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.65455\n",
            "Epoch 46/300\n",
            "5/5 - 0s - loss: 0.5438 - accuracy: 0.7951 - val_loss: 0.6360 - val_accuracy: 0.6545\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.65455\n",
            "Epoch 47/300\n",
            "5/5 - 0s - loss: 0.5400 - accuracy: 0.7951 - val_loss: 0.6361 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00047: val_accuracy improved from 0.65455 to 0.67273, saving model to /content/drive/MyDrive/Moodify/music_weights.hdf5\n",
            "Epoch 48/300\n",
            "5/5 - 0s - loss: 0.5362 - accuracy: 0.7951 - val_loss: 0.6340 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.67273\n",
            "Epoch 49/300\n",
            "5/5 - 0s - loss: 0.5327 - accuracy: 0.7951 - val_loss: 0.6277 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.67273\n",
            "Epoch 50/300\n",
            "5/5 - 0s - loss: 0.5295 - accuracy: 0.8032 - val_loss: 0.6272 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.67273\n",
            "Epoch 51/300\n",
            "5/5 - 0s - loss: 0.5259 - accuracy: 0.8114 - val_loss: 0.6259 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.67273\n",
            "Epoch 52/300\n",
            "5/5 - 0s - loss: 0.5235 - accuracy: 0.8073 - val_loss: 0.6197 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00052: val_accuracy improved from 0.67273 to 0.69091, saving model to /content/drive/MyDrive/Moodify/music_weights.hdf5\n",
            "Epoch 53/300\n",
            "5/5 - 0s - loss: 0.5202 - accuracy: 0.8114 - val_loss: 0.6200 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.69091\n",
            "Epoch 54/300\n",
            "5/5 - 0s - loss: 0.5174 - accuracy: 0.8134 - val_loss: 0.6196 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.69091\n",
            "Epoch 55/300\n",
            "5/5 - 0s - loss: 0.5144 - accuracy: 0.8114 - val_loss: 0.6210 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.69091\n",
            "Epoch 56/300\n",
            "5/5 - 0s - loss: 0.5121 - accuracy: 0.8134 - val_loss: 0.6173 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.69091\n",
            "Epoch 57/300\n",
            "5/5 - 0s - loss: 0.5099 - accuracy: 0.8174 - val_loss: 0.6168 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.69091\n",
            "Epoch 58/300\n",
            "5/5 - 0s - loss: 0.5072 - accuracy: 0.8195 - val_loss: 0.6142 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.69091\n",
            "Epoch 59/300\n",
            "5/5 - 0s - loss: 0.5059 - accuracy: 0.8195 - val_loss: 0.6166 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.69091\n",
            "Epoch 60/300\n",
            "5/5 - 0s - loss: 0.5028 - accuracy: 0.8134 - val_loss: 0.6132 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.69091\n",
            "Epoch 61/300\n",
            "5/5 - 0s - loss: 0.5007 - accuracy: 0.8174 - val_loss: 0.6087 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.69091\n",
            "Epoch 62/300\n",
            "5/5 - 0s - loss: 0.4990 - accuracy: 0.8195 - val_loss: 0.6055 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.69091\n",
            "Epoch 63/300\n",
            "5/5 - 0s - loss: 0.4970 - accuracy: 0.8174 - val_loss: 0.6063 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.69091\n",
            "Epoch 64/300\n",
            "5/5 - 0s - loss: 0.4956 - accuracy: 0.8154 - val_loss: 0.6052 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.69091\n",
            "Epoch 65/300\n",
            "5/5 - 0s - loss: 0.4936 - accuracy: 0.8174 - val_loss: 0.6028 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.69091\n",
            "Epoch 66/300\n",
            "5/5 - 0s - loss: 0.4916 - accuracy: 0.8174 - val_loss: 0.6064 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.69091\n",
            "Epoch 67/300\n",
            "5/5 - 0s - loss: 0.4899 - accuracy: 0.8154 - val_loss: 0.6078 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.69091\n",
            "Epoch 68/300\n",
            "5/5 - 0s - loss: 0.4883 - accuracy: 0.8174 - val_loss: 0.6083 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.69091\n",
            "Epoch 69/300\n",
            "5/5 - 0s - loss: 0.4879 - accuracy: 0.8215 - val_loss: 0.6014 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.69091\n",
            "Epoch 70/300\n",
            "5/5 - 0s - loss: 0.4853 - accuracy: 0.8215 - val_loss: 0.6000 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.69091\n",
            "Epoch 71/300\n",
            "5/5 - 0s - loss: 0.4844 - accuracy: 0.8174 - val_loss: 0.6031 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.69091\n",
            "Epoch 72/300\n",
            "5/5 - 0s - loss: 0.4830 - accuracy: 0.8195 - val_loss: 0.6040 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.69091\n",
            "Epoch 73/300\n",
            "5/5 - 0s - loss: 0.4813 - accuracy: 0.8195 - val_loss: 0.5995 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.69091\n",
            "Epoch 74/300\n",
            "5/5 - 0s - loss: 0.4803 - accuracy: 0.8256 - val_loss: 0.5992 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.69091\n",
            "Epoch 75/300\n",
            "5/5 - 0s - loss: 0.4789 - accuracy: 0.8256 - val_loss: 0.5983 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.69091\n",
            "Epoch 76/300\n",
            "5/5 - 0s - loss: 0.4775 - accuracy: 0.8235 - val_loss: 0.5937 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.69091\n",
            "Epoch 77/300\n",
            "5/5 - 0s - loss: 0.4769 - accuracy: 0.8215 - val_loss: 0.5936 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.69091\n",
            "Epoch 78/300\n",
            "5/5 - 0s - loss: 0.4757 - accuracy: 0.8256 - val_loss: 0.5966 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.69091\n",
            "Epoch 79/300\n",
            "5/5 - 0s - loss: 0.4754 - accuracy: 0.8235 - val_loss: 0.5912 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.69091\n",
            "Epoch 80/300\n",
            "5/5 - 0s - loss: 0.4736 - accuracy: 0.8235 - val_loss: 0.5947 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.69091\n",
            "Epoch 81/300\n",
            "5/5 - 0s - loss: 0.4734 - accuracy: 0.8215 - val_loss: 0.6013 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.69091\n",
            "Epoch 82/300\n",
            "5/5 - 0s - loss: 0.4720 - accuracy: 0.8215 - val_loss: 0.5945 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.69091\n",
            "Epoch 83/300\n",
            "5/5 - 0s - loss: 0.4712 - accuracy: 0.8215 - val_loss: 0.5948 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.69091\n",
            "Epoch 84/300\n",
            "5/5 - 0s - loss: 0.4711 - accuracy: 0.8195 - val_loss: 0.5876 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.69091\n",
            "Epoch 85/300\n",
            "5/5 - 0s - loss: 0.4692 - accuracy: 0.8235 - val_loss: 0.5923 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.69091\n",
            "Epoch 86/300\n",
            "5/5 - 0s - loss: 0.4688 - accuracy: 0.8235 - val_loss: 0.5962 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.69091\n",
            "Epoch 87/300\n",
            "5/5 - 0s - loss: 0.4675 - accuracy: 0.8276 - val_loss: 0.5933 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.69091\n",
            "Epoch 88/300\n",
            "5/5 - 0s - loss: 0.4676 - accuracy: 0.8235 - val_loss: 0.5953 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.69091\n",
            "Epoch 89/300\n",
            "5/5 - 0s - loss: 0.4661 - accuracy: 0.8215 - val_loss: 0.5947 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.69091\n",
            "Epoch 90/300\n",
            "5/5 - 0s - loss: 0.4653 - accuracy: 0.8256 - val_loss: 0.5903 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.69091\n",
            "Epoch 91/300\n",
            "5/5 - 0s - loss: 0.4647 - accuracy: 0.8215 - val_loss: 0.5933 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.69091\n",
            "Epoch 92/300\n",
            "5/5 - 0s - loss: 0.4641 - accuracy: 0.8235 - val_loss: 0.5913 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.69091\n",
            "Epoch 93/300\n",
            "5/5 - 0s - loss: 0.4635 - accuracy: 0.8235 - val_loss: 0.5895 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.69091\n",
            "Epoch 94/300\n",
            "5/5 - 0s - loss: 0.4629 - accuracy: 0.8256 - val_loss: 0.5907 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.69091\n",
            "Epoch 95/300\n",
            "5/5 - 0s - loss: 0.4623 - accuracy: 0.8256 - val_loss: 0.5911 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.69091\n",
            "Epoch 96/300\n",
            "5/5 - 0s - loss: 0.4620 - accuracy: 0.8235 - val_loss: 0.5957 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.69091\n",
            "Epoch 97/300\n",
            "5/5 - 0s - loss: 0.4610 - accuracy: 0.8235 - val_loss: 0.5883 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.69091\n",
            "Epoch 98/300\n",
            "5/5 - 0s - loss: 0.4602 - accuracy: 0.8235 - val_loss: 0.5865 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.69091\n",
            "Epoch 99/300\n",
            "5/5 - 0s - loss: 0.4601 - accuracy: 0.8235 - val_loss: 0.5837 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.69091\n",
            "Epoch 100/300\n",
            "5/5 - 0s - loss: 0.4596 - accuracy: 0.8296 - val_loss: 0.5872 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.69091\n",
            "Epoch 101/300\n",
            "5/5 - 0s - loss: 0.4586 - accuracy: 0.8235 - val_loss: 0.5891 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.69091\n",
            "Epoch 102/300\n",
            "5/5 - 0s - loss: 0.4588 - accuracy: 0.8256 - val_loss: 0.5942 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.69091\n",
            "Epoch 103/300\n",
            "5/5 - 0s - loss: 0.4578 - accuracy: 0.8215 - val_loss: 0.5874 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.69091\n",
            "Epoch 104/300\n",
            "5/5 - 0s - loss: 0.4573 - accuracy: 0.8256 - val_loss: 0.5836 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.69091\n",
            "Epoch 105/300\n",
            "5/5 - 0s - loss: 0.4572 - accuracy: 0.8256 - val_loss: 0.5841 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.69091\n",
            "Epoch 106/300\n",
            "5/5 - 0s - loss: 0.4565 - accuracy: 0.8215 - val_loss: 0.5908 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.69091\n",
            "Epoch 107/300\n",
            "5/5 - 0s - loss: 0.4559 - accuracy: 0.8215 - val_loss: 0.5871 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.69091\n",
            "Epoch 108/300\n",
            "5/5 - 0s - loss: 0.4556 - accuracy: 0.8256 - val_loss: 0.5871 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.69091\n",
            "Epoch 109/300\n",
            "5/5 - 0s - loss: 0.4550 - accuracy: 0.8215 - val_loss: 0.5871 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.69091\n",
            "Epoch 110/300\n",
            "5/5 - 0s - loss: 0.4550 - accuracy: 0.8235 - val_loss: 0.5878 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.69091\n",
            "Epoch 111/300\n",
            "5/5 - 0s - loss: 0.4553 - accuracy: 0.8195 - val_loss: 0.5915 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.69091\n",
            "Epoch 112/300\n",
            "5/5 - 0s - loss: 0.4539 - accuracy: 0.8235 - val_loss: 0.5823 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.69091\n",
            "Epoch 113/300\n",
            "5/5 - 0s - loss: 0.4539 - accuracy: 0.8276 - val_loss: 0.5839 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.69091\n",
            "Epoch 114/300\n",
            "5/5 - 0s - loss: 0.4528 - accuracy: 0.8256 - val_loss: 0.5859 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.69091\n",
            "Epoch 115/300\n",
            "5/5 - 0s - loss: 0.4524 - accuracy: 0.8235 - val_loss: 0.5861 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.69091\n",
            "Epoch 116/300\n",
            "5/5 - 0s - loss: 0.4517 - accuracy: 0.8235 - val_loss: 0.5822 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.69091\n",
            "Epoch 117/300\n",
            "5/5 - 0s - loss: 0.4520 - accuracy: 0.8235 - val_loss: 0.5809 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.69091\n",
            "Epoch 118/300\n",
            "5/5 - 0s - loss: 0.4513 - accuracy: 0.8235 - val_loss: 0.5832 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.69091\n",
            "Epoch 119/300\n",
            "5/5 - 0s - loss: 0.4507 - accuracy: 0.8215 - val_loss: 0.5832 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.69091\n",
            "Epoch 120/300\n",
            "5/5 - 0s - loss: 0.4507 - accuracy: 0.8256 - val_loss: 0.5860 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.69091\n",
            "Epoch 121/300\n",
            "5/5 - 0s - loss: 0.4510 - accuracy: 0.8296 - val_loss: 0.5871 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.69091\n",
            "Epoch 122/300\n",
            "5/5 - 0s - loss: 0.4505 - accuracy: 0.8316 - val_loss: 0.5829 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.69091\n",
            "Epoch 123/300\n",
            "5/5 - 0s - loss: 0.4492 - accuracy: 0.8235 - val_loss: 0.5830 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.69091\n",
            "Epoch 124/300\n",
            "5/5 - 0s - loss: 0.4492 - accuracy: 0.8195 - val_loss: 0.5839 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.69091\n",
            "Epoch 125/300\n",
            "5/5 - 0s - loss: 0.4496 - accuracy: 0.8215 - val_loss: 0.5814 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.69091\n",
            "Epoch 126/300\n",
            "5/5 - 0s - loss: 0.4487 - accuracy: 0.8215 - val_loss: 0.5810 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.69091\n",
            "Epoch 127/300\n",
            "5/5 - 0s - loss: 0.4502 - accuracy: 0.8276 - val_loss: 0.5805 - val_accuracy: 0.7091\n",
            "\n",
            "Epoch 00127: val_accuracy improved from 0.69091 to 0.70909, saving model to /content/drive/MyDrive/Moodify/music_weights.hdf5\n",
            "Epoch 128/300\n",
            "5/5 - 0s - loss: 0.4479 - accuracy: 0.8276 - val_loss: 0.5802 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.70909\n",
            "Epoch 129/300\n",
            "5/5 - 0s - loss: 0.4480 - accuracy: 0.8276 - val_loss: 0.5846 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.70909\n",
            "Epoch 130/300\n",
            "5/5 - 0s - loss: 0.4478 - accuracy: 0.8276 - val_loss: 0.5801 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.70909\n",
            "Epoch 131/300\n",
            "5/5 - 0s - loss: 0.4470 - accuracy: 0.8276 - val_loss: 0.5797 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.70909\n",
            "Epoch 132/300\n",
            "5/5 - 0s - loss: 0.4467 - accuracy: 0.8256 - val_loss: 0.5786 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.70909\n",
            "Epoch 133/300\n",
            "5/5 - 0s - loss: 0.4468 - accuracy: 0.8215 - val_loss: 0.5830 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.70909\n",
            "Epoch 134/300\n",
            "5/5 - 0s - loss: 0.4459 - accuracy: 0.8215 - val_loss: 0.5847 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.70909\n",
            "Epoch 135/300\n",
            "5/5 - 0s - loss: 0.4460 - accuracy: 0.8215 - val_loss: 0.5807 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.70909\n",
            "Epoch 136/300\n",
            "5/5 - 0s - loss: 0.4453 - accuracy: 0.8256 - val_loss: 0.5791 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.70909\n",
            "Epoch 137/300\n",
            "5/5 - 0s - loss: 0.4454 - accuracy: 0.8235 - val_loss: 0.5785 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.70909\n",
            "Epoch 138/300\n",
            "5/5 - 0s - loss: 0.4451 - accuracy: 0.8276 - val_loss: 0.5783 - val_accuracy: 0.7091\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.70909\n",
            "Epoch 139/300\n",
            "5/5 - 0s - loss: 0.4449 - accuracy: 0.8276 - val_loss: 0.5784 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.70909\n",
            "Epoch 140/300\n",
            "5/5 - 0s - loss: 0.4446 - accuracy: 0.8195 - val_loss: 0.5832 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.70909\n",
            "Epoch 141/300\n",
            "5/5 - 0s - loss: 0.4450 - accuracy: 0.8256 - val_loss: 0.5859 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.70909\n",
            "Epoch 142/300\n",
            "5/5 - 0s - loss: 0.4450 - accuracy: 0.8235 - val_loss: 0.5826 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.70909\n",
            "Epoch 143/300\n",
            "5/5 - 0s - loss: 0.4449 - accuracy: 0.8276 - val_loss: 0.5720 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.70909\n",
            "Epoch 144/300\n",
            "5/5 - 0s - loss: 0.4439 - accuracy: 0.8296 - val_loss: 0.5728 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.70909\n",
            "Epoch 145/300\n",
            "5/5 - 0s - loss: 0.4434 - accuracy: 0.8276 - val_loss: 0.5789 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.70909\n",
            "Epoch 146/300\n",
            "5/5 - 0s - loss: 0.4438 - accuracy: 0.8195 - val_loss: 0.5855 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.70909\n",
            "Epoch 147/300\n",
            "5/5 - 0s - loss: 0.4430 - accuracy: 0.8215 - val_loss: 0.5809 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.70909\n",
            "Epoch 148/300\n",
            "5/5 - 0s - loss: 0.4431 - accuracy: 0.8276 - val_loss: 0.5757 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.70909\n",
            "Epoch 149/300\n",
            "5/5 - 0s - loss: 0.4423 - accuracy: 0.8276 - val_loss: 0.5764 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.70909\n",
            "Epoch 150/300\n",
            "5/5 - 0s - loss: 0.4419 - accuracy: 0.8276 - val_loss: 0.5784 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.70909\n",
            "Epoch 151/300\n",
            "5/5 - 0s - loss: 0.4419 - accuracy: 0.8256 - val_loss: 0.5799 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.70909\n",
            "Epoch 152/300\n",
            "5/5 - 0s - loss: 0.4417 - accuracy: 0.8215 - val_loss: 0.5772 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.70909\n",
            "Epoch 153/300\n",
            "5/5 - 0s - loss: 0.4417 - accuracy: 0.8256 - val_loss: 0.5776 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.70909\n",
            "Epoch 154/300\n",
            "5/5 - 0s - loss: 0.4412 - accuracy: 0.8276 - val_loss: 0.5740 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.70909\n",
            "Epoch 155/300\n",
            "5/5 - 0s - loss: 0.4409 - accuracy: 0.8296 - val_loss: 0.5771 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.70909\n",
            "Epoch 156/300\n",
            "5/5 - 0s - loss: 0.4418 - accuracy: 0.8235 - val_loss: 0.5767 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.70909\n",
            "Epoch 157/300\n",
            "5/5 - 0s - loss: 0.4402 - accuracy: 0.8276 - val_loss: 0.5728 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.70909\n",
            "Epoch 158/300\n",
            "5/5 - 0s - loss: 0.4412 - accuracy: 0.8316 - val_loss: 0.5763 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.70909\n",
            "Epoch 159/300\n",
            "5/5 - 0s - loss: 0.4410 - accuracy: 0.8256 - val_loss: 0.5715 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.70909\n",
            "Epoch 160/300\n",
            "5/5 - 0s - loss: 0.4402 - accuracy: 0.8256 - val_loss: 0.5732 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.70909\n",
            "Epoch 161/300\n",
            "5/5 - 0s - loss: 0.4407 - accuracy: 0.8256 - val_loss: 0.5826 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.70909\n",
            "Epoch 162/300\n",
            "5/5 - 0s - loss: 0.4401 - accuracy: 0.8195 - val_loss: 0.5830 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.70909\n",
            "Epoch 163/300\n",
            "5/5 - 0s - loss: 0.4402 - accuracy: 0.8215 - val_loss: 0.5822 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.70909\n",
            "Epoch 164/300\n",
            "5/5 - 0s - loss: 0.4396 - accuracy: 0.8296 - val_loss: 0.5731 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.70909\n",
            "Epoch 165/300\n",
            "5/5 - 0s - loss: 0.4396 - accuracy: 0.8276 - val_loss: 0.5677 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.70909\n",
            "Epoch 166/300\n",
            "5/5 - 0s - loss: 0.4388 - accuracy: 0.8256 - val_loss: 0.5700 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.70909\n",
            "Epoch 167/300\n",
            "5/5 - 0s - loss: 0.4392 - accuracy: 0.8316 - val_loss: 0.5740 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.70909\n",
            "Epoch 168/300\n",
            "5/5 - 0s - loss: 0.4387 - accuracy: 0.8276 - val_loss: 0.5751 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.70909\n",
            "Epoch 169/300\n",
            "5/5 - 0s - loss: 0.4385 - accuracy: 0.8276 - val_loss: 0.5730 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.70909\n",
            "Epoch 170/300\n",
            "5/5 - 0s - loss: 0.4383 - accuracy: 0.8316 - val_loss: 0.5742 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.70909\n",
            "Epoch 171/300\n",
            "5/5 - 0s - loss: 0.4380 - accuracy: 0.8296 - val_loss: 0.5763 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.70909\n",
            "Epoch 172/300\n",
            "5/5 - 0s - loss: 0.4384 - accuracy: 0.8276 - val_loss: 0.5810 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.70909\n",
            "Epoch 173/300\n",
            "5/5 - 0s - loss: 0.4381 - accuracy: 0.8296 - val_loss: 0.5750 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.70909\n",
            "Epoch 174/300\n",
            "5/5 - 0s - loss: 0.4376 - accuracy: 0.8296 - val_loss: 0.5741 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.70909\n",
            "Epoch 175/300\n",
            "5/5 - 0s - loss: 0.4375 - accuracy: 0.8296 - val_loss: 0.5740 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.70909\n",
            "Epoch 176/300\n",
            "5/5 - 0s - loss: 0.4372 - accuracy: 0.8316 - val_loss: 0.5752 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.70909\n",
            "Epoch 177/300\n",
            "5/5 - 0s - loss: 0.4369 - accuracy: 0.8316 - val_loss: 0.5732 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.70909\n",
            "Epoch 178/300\n",
            "5/5 - 0s - loss: 0.4365 - accuracy: 0.8337 - val_loss: 0.5725 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.70909\n",
            "Epoch 179/300\n",
            "5/5 - 0s - loss: 0.4366 - accuracy: 0.8296 - val_loss: 0.5762 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.70909\n",
            "Epoch 180/300\n",
            "5/5 - 0s - loss: 0.4366 - accuracy: 0.8276 - val_loss: 0.5719 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.70909\n",
            "Epoch 181/300\n",
            "5/5 - 0s - loss: 0.4365 - accuracy: 0.8357 - val_loss: 0.5703 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.70909\n",
            "Epoch 182/300\n",
            "5/5 - 0s - loss: 0.4362 - accuracy: 0.8316 - val_loss: 0.5741 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.70909\n",
            "Epoch 183/300\n",
            "5/5 - 0s - loss: 0.4361 - accuracy: 0.8276 - val_loss: 0.5779 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.70909\n",
            "Epoch 184/300\n",
            "5/5 - 0s - loss: 0.4356 - accuracy: 0.8296 - val_loss: 0.5780 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.70909\n",
            "Epoch 185/300\n",
            "5/5 - 0s - loss: 0.4357 - accuracy: 0.8215 - val_loss: 0.5776 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.70909\n",
            "Epoch 186/300\n",
            "5/5 - 0s - loss: 0.4360 - accuracy: 0.8276 - val_loss: 0.5697 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.70909\n",
            "Epoch 187/300\n",
            "5/5 - 0s - loss: 0.4355 - accuracy: 0.8337 - val_loss: 0.5688 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.70909\n",
            "Epoch 188/300\n",
            "5/5 - 0s - loss: 0.4353 - accuracy: 0.8316 - val_loss: 0.5719 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.70909\n",
            "Epoch 189/300\n",
            "5/5 - 0s - loss: 0.4356 - accuracy: 0.8296 - val_loss: 0.5748 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.70909\n",
            "Epoch 190/300\n",
            "5/5 - 0s - loss: 0.4356 - accuracy: 0.8316 - val_loss: 0.5773 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.70909\n",
            "Epoch 191/300\n",
            "5/5 - 0s - loss: 0.4358 - accuracy: 0.8215 - val_loss: 0.5749 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.70909\n",
            "Epoch 192/300\n",
            "5/5 - 0s - loss: 0.4346 - accuracy: 0.8276 - val_loss: 0.5716 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.70909\n",
            "Epoch 193/300\n",
            "5/5 - 0s - loss: 0.4353 - accuracy: 0.8256 - val_loss: 0.5724 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.70909\n",
            "Epoch 194/300\n",
            "5/5 - 0s - loss: 0.4349 - accuracy: 0.8276 - val_loss: 0.5734 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.70909\n",
            "Epoch 195/300\n",
            "5/5 - 0s - loss: 0.4352 - accuracy: 0.8276 - val_loss: 0.5787 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.70909\n",
            "Epoch 196/300\n",
            "5/5 - 0s - loss: 0.4345 - accuracy: 0.8276 - val_loss: 0.5769 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.70909\n",
            "Epoch 197/300\n",
            "5/5 - 0s - loss: 0.4339 - accuracy: 0.8296 - val_loss: 0.5712 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.70909\n",
            "Epoch 198/300\n",
            "5/5 - 0s - loss: 0.4342 - accuracy: 0.8276 - val_loss: 0.5694 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.70909\n",
            "Epoch 199/300\n",
            "5/5 - 0s - loss: 0.4345 - accuracy: 0.8235 - val_loss: 0.5675 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.70909\n",
            "Epoch 200/300\n",
            "5/5 - 0s - loss: 0.4348 - accuracy: 0.8276 - val_loss: 0.5773 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.70909\n",
            "Epoch 201/300\n",
            "5/5 - 0s - loss: 0.4343 - accuracy: 0.8215 - val_loss: 0.5792 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.70909\n",
            "Epoch 202/300\n",
            "5/5 - 0s - loss: 0.4344 - accuracy: 0.8276 - val_loss: 0.5742 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.70909\n",
            "Epoch 203/300\n",
            "5/5 - 0s - loss: 0.4332 - accuracy: 0.8256 - val_loss: 0.5718 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.70909\n",
            "Epoch 204/300\n",
            "5/5 - 0s - loss: 0.4338 - accuracy: 0.8256 - val_loss: 0.5739 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.70909\n",
            "Epoch 205/300\n",
            "5/5 - 0s - loss: 0.4338 - accuracy: 0.8235 - val_loss: 0.5694 - val_accuracy: 0.6545\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.70909\n",
            "Epoch 206/300\n",
            "5/5 - 0s - loss: 0.4332 - accuracy: 0.8337 - val_loss: 0.5706 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.70909\n",
            "Epoch 207/300\n",
            "5/5 - 0s - loss: 0.4331 - accuracy: 0.8276 - val_loss: 0.5769 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.70909\n",
            "Epoch 208/300\n",
            "5/5 - 0s - loss: 0.4338 - accuracy: 0.8276 - val_loss: 0.5711 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.70909\n",
            "Epoch 209/300\n",
            "5/5 - 0s - loss: 0.4328 - accuracy: 0.8256 - val_loss: 0.5783 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.70909\n",
            "Epoch 210/300\n",
            "5/5 - 0s - loss: 0.4326 - accuracy: 0.8195 - val_loss: 0.5785 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.70909\n",
            "Epoch 211/300\n",
            "5/5 - 0s - loss: 0.4333 - accuracy: 0.8215 - val_loss: 0.5797 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.70909\n",
            "Epoch 212/300\n",
            "5/5 - 0s - loss: 0.4333 - accuracy: 0.8195 - val_loss: 0.5701 - val_accuracy: 0.6545\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.70909\n",
            "Epoch 213/300\n",
            "5/5 - 0s - loss: 0.4324 - accuracy: 0.8235 - val_loss: 0.5679 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.70909\n",
            "Epoch 214/300\n",
            "5/5 - 0s - loss: 0.4329 - accuracy: 0.8256 - val_loss: 0.5762 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.70909\n",
            "Epoch 215/300\n",
            "5/5 - 0s - loss: 0.4328 - accuracy: 0.8276 - val_loss: 0.5740 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.70909\n",
            "Epoch 216/300\n",
            "5/5 - 0s - loss: 0.4322 - accuracy: 0.8296 - val_loss: 0.5731 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.70909\n",
            "Epoch 217/300\n",
            "5/5 - 0s - loss: 0.4317 - accuracy: 0.8296 - val_loss: 0.5735 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.70909\n",
            "Epoch 218/300\n",
            "5/5 - 0s - loss: 0.4319 - accuracy: 0.8276 - val_loss: 0.5732 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.70909\n",
            "Epoch 219/300\n",
            "5/5 - 0s - loss: 0.4324 - accuracy: 0.8256 - val_loss: 0.5692 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.70909\n",
            "Epoch 220/300\n",
            "5/5 - 0s - loss: 0.4316 - accuracy: 0.8276 - val_loss: 0.5709 - val_accuracy: 0.6545\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.70909\n",
            "Epoch 221/300\n",
            "5/5 - 0s - loss: 0.4320 - accuracy: 0.8235 - val_loss: 0.5737 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.70909\n",
            "Epoch 222/300\n",
            "5/5 - 0s - loss: 0.4319 - accuracy: 0.8276 - val_loss: 0.5755 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.70909\n",
            "Epoch 223/300\n",
            "5/5 - 0s - loss: 0.4311 - accuracy: 0.8276 - val_loss: 0.5753 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.70909\n",
            "Epoch 224/300\n",
            "5/5 - 0s - loss: 0.4320 - accuracy: 0.8296 - val_loss: 0.5792 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.70909\n",
            "Epoch 225/300\n",
            "5/5 - 0s - loss: 0.4320 - accuracy: 0.8276 - val_loss: 0.5694 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.70909\n",
            "Epoch 226/300\n",
            "5/5 - 0s - loss: 0.4312 - accuracy: 0.8256 - val_loss: 0.5706 - val_accuracy: 0.6545\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.70909\n",
            "Epoch 227/300\n",
            "5/5 - 0s - loss: 0.4307 - accuracy: 0.8276 - val_loss: 0.5719 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.70909\n",
            "Epoch 228/300\n",
            "5/5 - 0s - loss: 0.4314 - accuracy: 0.8256 - val_loss: 0.5769 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.70909\n",
            "Epoch 229/300\n",
            "5/5 - 0s - loss: 0.4313 - accuracy: 0.8276 - val_loss: 0.5730 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.70909\n",
            "Epoch 230/300\n",
            "5/5 - 0s - loss: 0.4305 - accuracy: 0.8256 - val_loss: 0.5684 - val_accuracy: 0.6545\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.70909\n",
            "Epoch 231/300\n",
            "5/5 - 0s - loss: 0.4320 - accuracy: 0.8276 - val_loss: 0.5746 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.70909\n",
            "Epoch 232/300\n",
            "5/5 - 0s - loss: 0.4307 - accuracy: 0.8296 - val_loss: 0.5678 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.70909\n",
            "Epoch 233/300\n",
            "5/5 - 0s - loss: 0.4304 - accuracy: 0.8296 - val_loss: 0.5696 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.70909\n",
            "Epoch 234/300\n",
            "5/5 - 0s - loss: 0.4306 - accuracy: 0.8256 - val_loss: 0.5682 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.70909\n",
            "Epoch 235/300\n",
            "5/5 - 0s - loss: 0.4302 - accuracy: 0.8276 - val_loss: 0.5675 - val_accuracy: 0.6545\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.70909\n",
            "Epoch 236/300\n",
            "5/5 - 0s - loss: 0.4301 - accuracy: 0.8256 - val_loss: 0.5733 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.70909\n",
            "Epoch 237/300\n",
            "5/5 - 0s - loss: 0.4300 - accuracy: 0.8256 - val_loss: 0.5781 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.70909\n",
            "Epoch 238/300\n",
            "5/5 - 0s - loss: 0.4305 - accuracy: 0.8256 - val_loss: 0.5714 - val_accuracy: 0.6545\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.70909\n",
            "Epoch 239/300\n",
            "5/5 - 0s - loss: 0.4298 - accuracy: 0.8256 - val_loss: 0.5738 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.70909\n",
            "Epoch 240/300\n",
            "5/5 - 0s - loss: 0.4294 - accuracy: 0.8235 - val_loss: 0.5714 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.70909\n",
            "Epoch 241/300\n",
            "5/5 - 0s - loss: 0.4296 - accuracy: 0.8256 - val_loss: 0.5752 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.70909\n",
            "Epoch 242/300\n",
            "5/5 - 0s - loss: 0.4295 - accuracy: 0.8296 - val_loss: 0.5736 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.70909\n",
            "Epoch 243/300\n",
            "5/5 - 0s - loss: 0.4297 - accuracy: 0.8296 - val_loss: 0.5682 - val_accuracy: 0.6545\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.70909\n",
            "Epoch 244/300\n",
            "5/5 - 0s - loss: 0.4296 - accuracy: 0.8296 - val_loss: 0.5685 - val_accuracy: 0.6545\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.70909\n",
            "Epoch 245/300\n",
            "5/5 - 0s - loss: 0.4291 - accuracy: 0.8256 - val_loss: 0.5748 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.70909\n",
            "Epoch 246/300\n",
            "5/5 - 0s - loss: 0.4293 - accuracy: 0.8235 - val_loss: 0.5774 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.70909\n",
            "Epoch 247/300\n",
            "5/5 - 0s - loss: 0.4293 - accuracy: 0.8215 - val_loss: 0.5768 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.70909\n",
            "Epoch 248/300\n",
            "5/5 - 0s - loss: 0.4294 - accuracy: 0.8276 - val_loss: 0.5698 - val_accuracy: 0.6545\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.70909\n",
            "Epoch 249/300\n",
            "5/5 - 0s - loss: 0.4292 - accuracy: 0.8256 - val_loss: 0.5657 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.70909\n",
            "Epoch 250/300\n",
            "5/5 - 0s - loss: 0.4294 - accuracy: 0.8316 - val_loss: 0.5720 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.70909\n",
            "Epoch 251/300\n",
            "5/5 - 0s - loss: 0.4286 - accuracy: 0.8276 - val_loss: 0.5747 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.70909\n",
            "Epoch 252/300\n",
            "5/5 - 0s - loss: 0.4289 - accuracy: 0.8235 - val_loss: 0.5758 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.70909\n",
            "Epoch 253/300\n",
            "5/5 - 0s - loss: 0.4292 - accuracy: 0.8235 - val_loss: 0.5723 - val_accuracy: 0.6545\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.70909\n",
            "Epoch 254/300\n",
            "5/5 - 0s - loss: 0.4285 - accuracy: 0.8215 - val_loss: 0.5747 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.70909\n",
            "Epoch 255/300\n",
            "5/5 - 0s - loss: 0.4288 - accuracy: 0.8276 - val_loss: 0.5729 - val_accuracy: 0.6545\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.70909\n",
            "Epoch 256/300\n",
            "5/5 - 0s - loss: 0.4287 - accuracy: 0.8235 - val_loss: 0.5741 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.70909\n",
            "Epoch 257/300\n",
            "5/5 - 0s - loss: 0.4281 - accuracy: 0.8256 - val_loss: 0.5700 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.70909\n",
            "Epoch 258/300\n",
            "5/5 - 0s - loss: 0.4284 - accuracy: 0.8256 - val_loss: 0.5726 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.70909\n",
            "Epoch 259/300\n",
            "5/5 - 0s - loss: 0.4282 - accuracy: 0.8296 - val_loss: 0.5664 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.70909\n",
            "Epoch 260/300\n",
            "5/5 - 0s - loss: 0.4283 - accuracy: 0.8256 - val_loss: 0.5696 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.70909\n",
            "Epoch 261/300\n",
            "5/5 - 0s - loss: 0.4279 - accuracy: 0.8276 - val_loss: 0.5727 - val_accuracy: 0.6545\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.70909\n",
            "Epoch 262/300\n",
            "5/5 - 0s - loss: 0.4275 - accuracy: 0.8235 - val_loss: 0.5719 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.70909\n",
            "Epoch 263/300\n",
            "5/5 - 0s - loss: 0.4278 - accuracy: 0.8235 - val_loss: 0.5753 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.70909\n",
            "Epoch 264/300\n",
            "5/5 - 0s - loss: 0.4280 - accuracy: 0.8256 - val_loss: 0.5733 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.70909\n",
            "Epoch 265/300\n",
            "5/5 - 0s - loss: 0.4277 - accuracy: 0.8256 - val_loss: 0.5685 - val_accuracy: 0.6545\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.70909\n",
            "Epoch 266/300\n",
            "5/5 - 0s - loss: 0.4279 - accuracy: 0.8256 - val_loss: 0.5712 - val_accuracy: 0.6545\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.70909\n",
            "Epoch 267/300\n",
            "5/5 - 0s - loss: 0.4283 - accuracy: 0.8256 - val_loss: 0.5766 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.70909\n",
            "Epoch 268/300\n",
            "5/5 - 0s - loss: 0.4277 - accuracy: 0.8256 - val_loss: 0.5728 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.70909\n",
            "Epoch 269/300\n",
            "5/5 - 0s - loss: 0.4279 - accuracy: 0.8195 - val_loss: 0.5672 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.70909\n",
            "Epoch 270/300\n",
            "5/5 - 0s - loss: 0.4271 - accuracy: 0.8256 - val_loss: 0.5681 - val_accuracy: 0.6545\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.70909\n",
            "Epoch 271/300\n",
            "5/5 - 0s - loss: 0.4270 - accuracy: 0.8235 - val_loss: 0.5718 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.70909\n",
            "Epoch 272/300\n",
            "5/5 - 0s - loss: 0.4274 - accuracy: 0.8215 - val_loss: 0.5669 - val_accuracy: 0.6545\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.70909\n",
            "Epoch 273/300\n",
            "5/5 - 0s - loss: 0.4271 - accuracy: 0.8215 - val_loss: 0.5715 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.70909\n",
            "Epoch 274/300\n",
            "5/5 - 0s - loss: 0.4272 - accuracy: 0.8235 - val_loss: 0.5749 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.70909\n",
            "Epoch 275/300\n",
            "5/5 - 0s - loss: 0.4271 - accuracy: 0.8235 - val_loss: 0.5693 - val_accuracy: 0.6545\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.70909\n",
            "Epoch 276/300\n",
            "5/5 - 0s - loss: 0.4267 - accuracy: 0.8174 - val_loss: 0.5715 - val_accuracy: 0.6545\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.70909\n",
            "Epoch 277/300\n",
            "5/5 - 0s - loss: 0.4265 - accuracy: 0.8215 - val_loss: 0.5702 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.70909\n",
            "Epoch 278/300\n",
            "5/5 - 0s - loss: 0.4267 - accuracy: 0.8195 - val_loss: 0.5699 - val_accuracy: 0.6545\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.70909\n",
            "Epoch 279/300\n",
            "5/5 - 0s - loss: 0.4272 - accuracy: 0.8235 - val_loss: 0.5755 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.70909\n",
            "Epoch 280/300\n",
            "5/5 - 0s - loss: 0.4266 - accuracy: 0.8256 - val_loss: 0.5736 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.70909\n",
            "Epoch 281/300\n",
            "5/5 - 0s - loss: 0.4260 - accuracy: 0.8215 - val_loss: 0.5707 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.70909\n",
            "Epoch 282/300\n",
            "5/5 - 0s - loss: 0.4269 - accuracy: 0.8235 - val_loss: 0.5632 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.70909\n",
            "Epoch 283/300\n",
            "5/5 - 0s - loss: 0.4266 - accuracy: 0.8215 - val_loss: 0.5692 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.70909\n",
            "Epoch 284/300\n",
            "5/5 - 0s - loss: 0.4262 - accuracy: 0.8235 - val_loss: 0.5710 - val_accuracy: 0.6545\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.70909\n",
            "Epoch 285/300\n",
            "5/5 - 0s - loss: 0.4273 - accuracy: 0.8215 - val_loss: 0.5780 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.70909\n",
            "Epoch 286/300\n",
            "5/5 - 0s - loss: 0.4264 - accuracy: 0.8215 - val_loss: 0.5733 - val_accuracy: 0.6545\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.70909\n",
            "Epoch 287/300\n",
            "5/5 - 0s - loss: 0.4259 - accuracy: 0.8235 - val_loss: 0.5703 - val_accuracy: 0.6545\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.70909\n",
            "Epoch 288/300\n",
            "5/5 - 0s - loss: 0.4261 - accuracy: 0.8195 - val_loss: 0.5664 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.70909\n",
            "Epoch 289/300\n",
            "5/5 - 0s - loss: 0.4260 - accuracy: 0.8235 - val_loss: 0.5682 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.70909\n",
            "Epoch 290/300\n",
            "5/5 - 0s - loss: 0.4259 - accuracy: 0.8235 - val_loss: 0.5713 - val_accuracy: 0.6545\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.70909\n",
            "Epoch 291/300\n",
            "5/5 - 0s - loss: 0.4262 - accuracy: 0.8195 - val_loss: 0.5753 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.70909\n",
            "Epoch 292/300\n",
            "5/5 - 0s - loss: 0.4256 - accuracy: 0.8215 - val_loss: 0.5733 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.70909\n",
            "Epoch 293/300\n",
            "5/5 - 0s - loss: 0.4263 - accuracy: 0.8215 - val_loss: 0.5719 - val_accuracy: 0.6545\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.70909\n",
            "Epoch 294/300\n",
            "5/5 - 0s - loss: 0.4258 - accuracy: 0.8215 - val_loss: 0.5674 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.70909\n",
            "Epoch 295/300\n",
            "5/5 - 0s - loss: 0.4260 - accuracy: 0.8215 - val_loss: 0.5665 - val_accuracy: 0.6909\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.70909\n",
            "Epoch 296/300\n",
            "5/5 - 0s - loss: 0.4254 - accuracy: 0.8174 - val_loss: 0.5700 - val_accuracy: 0.6545\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.70909\n",
            "Epoch 297/300\n",
            "5/5 - 0s - loss: 0.4254 - accuracy: 0.8195 - val_loss: 0.5707 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.70909\n",
            "Epoch 298/300\n",
            "5/5 - 0s - loss: 0.4252 - accuracy: 0.8215 - val_loss: 0.5744 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.70909\n",
            "Epoch 299/300\n",
            "5/5 - 0s - loss: 0.4253 - accuracy: 0.8235 - val_loss: 0.5757 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.70909\n",
            "Epoch 300/300\n",
            "5/5 - 0s - loss: 0.4253 - accuracy: 0.8215 - val_loss: 0.5728 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.70909\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpOVPDJF0oL_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fe28462-41ec-4555-8a85-9dd23c5e30d4"
      },
      "source": [
        "model.load_weights(\"/content/drive/MyDrive/Moodify/music_weights.hdf5\")\n",
        "model.compile(optimizer=opt,loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
        "model.evaluate(X_test,Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3599 - accuracy: 0.8411\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.378061980009079, 0.8333333134651184]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    }
  ]
}